# HoloKit Low Latency Tracking

HoloKit uses ARKit's spatial tracking feature to get the 6DoF (Degrees of Freedom) pose of the user's head. ARKit, designed for iOS devices, is primarily tailored for screen-based AR experiences, where real-time camera background images are displayed on the screen. To ensure stability, the mobile device introduces a delay in the camera video stream, enhancing the integration of real and virtual content. However, in the case of HoloKit, an optical-see-through (OST) headset, this delay causes a misalignment between virtual content and the real world, especially noticeable when the user moves their head.

The objective of the HoloKit low latency tracking algorithm is to reduce latency by using the device's raw accelerometer and gyroscope data to refine ARKit's output pose data. [Aryzon SDK](https://github.com/Aryzon/unity-sdk)'s approach addresses the limitations of [Google Cardboard](https://github.com/googlevr/cardboard), which relies solely on device accelerometer and gyroscope data for real-time 3DoF pose calculations. Aryzon SDK's approach enhanced this by integrating ARKit's 6DoF pose data with Google Cardboard's 3DoF data, creating a fused 6DoF pose with lower latency than ARKit's standalone output. Following this model, we adapted and packed the necessary native Objective-C++ code from [Aryzon's modified Google Cardboard repository](https://github.com/Aryzon/cardboard/tree/main). Additionally, we wrote a bridge file to facilitate two-way marshalling between unmanaged (Objective-C++) and managed (C#) codebases.
